{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 most popular languages\n",
    "# languages = ['JavaScript', 'Java', 'HTML', 'Python', 'PHP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "from os import path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.copy() to copy a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Top Language Used - Done\n",
    "### Scrape body of README.md - In Progress\n",
    "### Put into DataFrame - Not Done at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://github.com/trending', \n",
    "        'https://github.com/collections/clean-code-linters', \n",
    "        'https://github.com/collections/open-journalism', \n",
    "        'https://github.com/collections/design-essentials',\n",
    "        'https://github.com/collections/music',\n",
    "        'https://github.com/collections/devops-tools',\n",
    "        'https://github.com/collections/hacking-minecraft',\n",
    "        'https://github.com/collections/javascript-game-engines',\n",
    "        'https://github.com/collections/learn-to-code',\n",
    "        'https://github.com/collections/machine-learning',\n",
    "        'https://github.com/collections/net-neutrality',\n",
    "        \n",
    "        \n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.Series(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           https://github.com/trending\n",
       "1     https://github.com/collections/clean-code-linters\n",
       "2        https://github.com/collections/open-journalism\n",
       "3      https://github.com/collections/design-essentials\n",
       "4                  https://github.com/collections/music\n",
       "5           https://github.com/collections/devops-tools\n",
       "6      https://github.com/collections/hacking-minecraft\n",
       "7     https://github.com/collections/javascript-game...\n",
       "8          https://github.com/collections/learn-to-code\n",
       "9       https://github.com/collections/machine-learning\n",
       "10        https://github.com/collections/net-neutrality\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_repo_names():    \n",
    "    headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "    urls = []\n",
    "    \n",
    "    for h1 in soup.find_all('h1'):\n",
    "        urls.append((re.sub(r'\\s', '',h1.text)))\n",
    "    urls.pop(0)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "retrieve_repo_names() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-d609daae74b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0murls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_repo_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: retrieve_repo_names() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "urls.apply(retrieve_repo_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "response = get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# title = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"h0-mktg\">Trending</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/bytefury/crater\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        bytefury /\n",
      "</span>\n",
      "\n",
      "\n",
      "      crater\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/marblexu/PythonPlantsVsZombies\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        marblexu /\n",
      "</span>\n",
      "\n",
      "\n",
      "      PythonPlantsVsZombies\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/renjie-feng-trash/fengrenjie\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        renjie-feng-trash /\n",
      "</span>\n",
      "\n",
      "\n",
      "      fengrenjie\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/docker-slim/docker-slim\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        docker-slim /\n",
      "</span>\n",
      "\n",
      "\n",
      "      docker-slim\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/alphaSeclab/awesome-reverse-engineering\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        alphaSeclab /\n",
      "</span>\n",
      "\n",
      "\n",
      "      awesome-reverse-engineering\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/ryanhanwu/How-To-Ask-Questions-The-Smart-Way\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        ryanhanwu /\n",
      "</span>\n",
      "\n",
      "\n",
      "      How-To-Ask-Questions-The-Smart-Way\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/kdn251/interviews\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        kdn251 /\n",
      "</span>\n",
      "\n",
      "\n",
      "      interviews\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/AobingJava/JavaFamily\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        AobingJava /\n",
      "</span>\n",
      "\n",
      "\n",
      "      JavaFamily\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/sudomesh/disaster-radio\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        sudomesh /\n",
      "</span>\n",
      "\n",
      "\n",
      "      disaster-radio\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/flutter/flutter\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        flutter /\n",
      "</span>\n",
      "\n",
      "\n",
      "      flutter\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/RomelTorres/alpha_vantage\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        RomelTorres /\n",
      "</span>\n",
      "\n",
      "\n",
      "      alpha_vantage\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/Asabeneh/30-Days-Of-Python\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        Asabeneh /\n",
      "</span>\n",
      "\n",
      "\n",
      "      30-Days-Of-Python\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/getify/You-Dont-Know-JS\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        getify /\n",
      "</span>\n",
      "\n",
      "\n",
      "      You-Dont-Know-JS\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/TheAlgorithms/Python\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        TheAlgorithms /\n",
      "</span>\n",
      "\n",
      "\n",
      "      Python\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/dhondta/dronesploit\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        dhondta /\n",
      "</span>\n",
      "\n",
      "\n",
      "      dronesploit\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/ElemeFE/element\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        ElemeFE /\n",
      "</span>\n",
      "\n",
      "\n",
      "      element\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/lydiahallie/javascript-questions\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        lydiahallie /\n",
      "</span>\n",
      "\n",
      "\n",
      "      javascript-questions\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/robfig/cron\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        robfig /\n",
      "</span>\n",
      "\n",
      "\n",
      "      cron\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/wuyouzhuguli/SpringAll\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        wuyouzhuguli /\n",
      "</span>\n",
      "\n",
      "\n",
      "      SpringAll\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/dylanaraps/pure-bash-bible\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        dylanaraps /\n",
      "</span>\n",
      "\n",
      "\n",
      "      pure-bash-bible\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/formulahendry/955.WLB\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        formulahendry /\n",
      "</span>\n",
      "\n",
      "\n",
      "      955.WLB\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/testerSunshine/12306\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        testerSunshine /\n",
      "</span>\n",
      "\n",
      "\n",
      "      12306\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/google/mediapipe\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        google /\n",
      "</span>\n",
      "\n",
      "\n",
      "      mediapipe\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/hashicorp/terraform\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        hashicorp /\n",
      "</span>\n",
      "\n",
      "\n",
      "      terraform\n",
      "</a>\n",
      "</h1>\n",
      "<h1 class=\"h3 lh-condensed\">\n",
      "<a href=\"/libra/libra\">\n",
      "<svg aria-label=\"repo\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" role=\"img\" version=\"1.1\" viewbox=\"0 0 12 16\" width=\"12\"><path d=\"M4 9H3V8h1v1zm0-3H3v1h1V6zm0-2H3v1h1V4zm0-2H3v1h1V2zm8-1v12c0 .55-.45 1-1 1H6v2l-1.5-1.5L3 16v-2H1c-.55 0-1-.45-1-1V1c0-.55.45-1 1-1h10c.55 0 1 .45 1 1zm-1 10H1v2h2v-1h3v1h5v-2zm0-10H2v9h9V1z\" fill-rule=\"evenodd\"></path></svg>\n",
      "<span class=\"text-normal\">\n",
      "        libra /\n",
      "</span>\n",
      "\n",
      "\n",
      "      libra\n",
      "</a>\n",
      "</h1>\n"
     ]
    }
   ],
   "source": [
    "for h1 in soup.find_all('h1'):\n",
    "    urls.append((re.sub(r'\\s', '',h1.text)))\n",
    "#     urls.pop(0)\n",
    "    print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d51763bc3703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "soup.find('span', class_= 'lang').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4238169838f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Box-body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "body = soup.find('div', class_= 'Box-body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string):\n",
    "    words = string.split()\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "    joined_words = ' '.join(filtered_words)\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_list():\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    urls = get_urls()\n",
    "    \n",
    "    for url in urls:\n",
    "        headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "        response = get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title = urls[url]\n",
    "        language = soup.find('span', class_= 'lang').text\n",
    "        body = soup.find('div', class_= 'Box-body').text\n",
    "\n",
    "        data = {\n",
    "            'title' : title,\n",
    "            'language' : language,\n",
    "            'body' : body\n",
    "        }\n",
    "\n",
    "        output.append(data)\n",
    "        \n",
    "#       for h1 in soup.find_all('h1'):\n",
    "#           urls.append((re.sub(r'\\s', '',h1.text)))\n",
    "#           urls.pop(0)\n",
    "#       return urls\n",
    "    \n",
    "    return output\n",
    "\n",
    "# def get_links():\n",
    "# #     url = 'https://github.com/trending'\n",
    "# #     url = 'https://github.com/collections/clean-code-linters'\n",
    "# #     url = 'https://github.com/collections/open-journalism'\n",
    "# #     url = 'https://github.com/collections/design-essentials'\n",
    "# #     url = 'https://github.com/collections/music'\n",
    "#     url = 'https://github.com/collections/devops-tools'\n",
    "#     headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "#     response = get(url, headers=headers)\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "#     urls = []\n",
    "    \n",
    "#     for h1 in soup.find_all('h1'):\n",
    "#         urls.append((re.sub(r'\\s', '',h1.text)))\n",
    "#     urls.pop(0)\n",
    "#     return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-078b557b1adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-cc7d4e7e7337>\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_urls' is not defined"
     ]
    }
   ],
   "source": [
    "get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/trending',\n",
       " 'https://github.com/collections/clean-code-linters',\n",
       " 'https://github.com/collections/open-journalism',\n",
       " 'https://github.com/collections/design-essentials',\n",
       " 'https://github.com/collections/music',\n",
       " 'https://github.com/collections/devops-tools',\n",
       " 'https://github.com/collections/hacking-minecraft',\n",
       " 'https://github.com/collections/javascript-game-engines',\n",
       " 'https://github.com/collections/learn-to-code',\n",
       " 'https://github.com/collections/machine-learning',\n",
       " 'https://github.com/collections/net-neutrality',\n",
       " 'Trending',\n",
       " 'bytefury/crater',\n",
       " 'marblexu/PythonPlantsVsZombies',\n",
       " 'renjie-feng-trash/fengrenjie',\n",
       " 'docker-slim/docker-slim',\n",
       " 'alphaSeclab/awesome-reverse-engineering',\n",
       " 'ryanhanwu/How-To-Ask-Questions-The-Smart-Way',\n",
       " 'kdn251/interviews',\n",
       " 'AobingJava/JavaFamily',\n",
       " 'sudomesh/disaster-radio',\n",
       " 'flutter/flutter',\n",
       " 'RomelTorres/alpha_vantage',\n",
       " 'Asabeneh/30-Days-Of-Python',\n",
       " 'getify/You-Dont-Know-JS',\n",
       " 'TheAlgorithms/Python',\n",
       " 'dhondta/dronesploit',\n",
       " 'ElemeFE/element',\n",
       " 'lydiahallie/javascript-questions',\n",
       " 'robfig/cron',\n",
       " 'wuyouzhuguli/SpringAll',\n",
       " 'dylanaraps/pure-bash-bible',\n",
       " 'formulahendry/955.WLB',\n",
       " 'testerSunshine/12306',\n",
       " 'google/mediapipe',\n",
       " 'hashicorp/terraform',\n",
       " 'libra/libra']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_urls():\n",
    "    empty = []\n",
    "    urls = get_urls()\n",
    "    for url in urls:\n",
    "        base_url = 'https://github.com/{}'.format(url)\n",
    "        empty.append(base_url)\n",
    "    return empty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a5078f9b2f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c8905474e524>\u001b[0m in \u001b[0;36mcreate_urls\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mempty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://github.com/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_urls' is not defined"
     ]
    }
   ],
   "source": [
    "create_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls():\n",
    "    urls = [\n",
    "        'https://github.com/collections/clean-code-linters', \n",
    "        'https://github.com/collections/open-journalism', \n",
    "        'https://github.com/collections/design-essentials',\n",
    "        'https://github.com/collections/music',\n",
    "        'https://github.com/collections/devops-tools'\n",
    "       ]\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for url in urls:\n",
    "         output.extend(get_links(url))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_links() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-08bddd440a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-de6fddb0b311>\u001b[0m in \u001b[0;36mget_urls\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m          \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_links() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "get_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a7f4a5366567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_new_request' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b79b4e19e269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_new_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'make_new_request' is not defined"
     ]
    }
   ],
   "source": [
    "x = make_new_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending'\n",
    "# url = 'https://github.com/collections/clean-code-linters'\n",
    "# url = 'https://github.com/collections/open-journalism'\n",
    "# url = 'https://github.com/collections/design-essentials'\n",
    "# url = 'https://github.com/collections/music'\n",
    "# url = 'https://github.com/collections/devops-tools'\n",
    "\n",
    "headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "\n",
    "response = get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response.content)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find('span', class_= 'lang').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('span', class_= 'lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3aac31c447d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Box-body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "soup.find('div', class_= 'Box-body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links():\n",
    "    \n",
    "    #     url = 'https://github.com/trending'\n",
    "#     url = 'https://github.com/collections/clean-code-linters'\n",
    "#     url = 'https://github.com/collections/open-journalism'\n",
    "#     url = 'https://github.com/collections/design-essentials'\n",
    "#     url = 'https://github.com/collections/music'\n",
    "#     url = 'https://github.com/collections/devops-tools'\n",
    "    headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    urls = []\n",
    "    \n",
    "    for h1 in soup.find_all('h1'):\n",
    "        urls.append((re.sub(r'\\s', '',h1.text)))\n",
    "    urls.pop(0)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['puppetlabs/puppet',\n",
       " 'chef/chef',\n",
       " 'ansible/ansible',\n",
       " 'saltstack/salt',\n",
       " 'hashicorp/vagrant',\n",
       " 'openstack/openstack',\n",
       " 'moby/moby',\n",
       " 'capistrano/capistrano',\n",
       " 'statsd/statsd',\n",
       " 'graphite-project/graphite-web',\n",
       " 'elastic/logstash',\n",
       " 'fabric/fabric',\n",
       " 'grafana/grafana',\n",
       " 'StackStorm/st2',\n",
       " 'openshift/origin',\n",
       " 'getsentry/sentry',\n",
       " 'deployphp/deployer',\n",
       " 'kubernetes/kubernetes',\n",
       " 'netdata/netdata',\n",
       " 'cloud66-oss/habitus']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repo_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-dee75bab4e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'repo_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(repo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_list = ['AIDungeon/AIDungeon',\n",
    "             'rclone/rclone',\n",
    "             'marblexu/PythonPlantsVsZombies',\n",
    "             'redox-os/orbtk',\n",
    "             'sailay1996/UAC_Bypass_In_The_Wild',\n",
    "             'ruanyf/weekly',\n",
    "             'alirezadir/Production-Level-Deep-Learning',\n",
    "             'sdmg15/Best-websites-a-programmer-should-visit',\n",
    "             'practicalAI/practicalAI',\n",
    "             'HuaweiJoke/Huawei-Joke',\n",
    "             'trekhleb/javascript-algorithms',\n",
    "             '521xueweihan/HelloGitHub',\n",
    "             'getify/You-Dont-Know-JS',\n",
    "             'kdn251/interviews',\n",
    "             'eavichay/microfronts',\n",
    "             'goldbergyoni/nodebestpractices',\n",
    "             'wuyouzhuguli/SpringAll',\n",
    "             'halo-dev/halo',\n",
    "             'serverless/serverless',\n",
    "             'prometheus/client_golang',\n",
    "             'VMadalin/kotlin-sample-app',\n",
    "             'davidfowl/FeatherHttp',\n",
    "             '0vercl0k/CVE-2019-11708',\n",
    "             'mrdoob/three.js',\n",
    "             'OfficeDev/office-ui-fabric-react',\n",
    "             'standard/standard',\n",
    "             'eslint/eslint',\n",
    "             'jshint/jshint',\n",
    "             'clutchski/coffeelint',\n",
    "             'csscomb/csscomb.js',\n",
    "             'sds/scss-lint',\n",
    "             'htmlhint/HTMLHint',\n",
    "             'validator/validator',\n",
    "             'CSSLint/csslint',\n",
    "             'PyCQA/pycodestyle',\n",
    "             'PyCQA/flake8',\n",
    "             'psf/black',\n",
    "             'checkstyle/checkstyle',\n",
    "             'rubocop-hq/rubocop',\n",
    "             'oclint/oclint',\n",
    "             'golang/lint',\n",
    "             'ndmitchell/hlint',\n",
    "             'coala/coala',\n",
    "             'pre-commit/pre-commit',\n",
    "             'innogames/igcommit',\n",
    "             'fivethirtyeight/data',\n",
    "             'datadesk/notebooks',\n",
    "             'nytimes/objective-c-style-guide',\n",
    "             'newsapps/beeswithmachineguns',\n",
    "             'voxmedia/meme',\n",
    "             'propublica/guides',\n",
    "             'censusreporter/censusreporter',\n",
    "             'nprapps/app-template',\n",
    "             'TimeMagazineLabs/babynames',\n",
    "             'guardian/frontend',\n",
    "             'dukechronicle/chronline',\n",
    "             'BloombergMedia/whatiscode',\n",
    "             'times/cardkit',\n",
    "             'mkiser/WTFJHT',\n",
    "             'twbs/bootstrap',\n",
    "             'daneden/animate.css',\n",
    "             'nathansmith/960-Grid-System',\n",
    "             'necolas/normalize.css',\n",
    "             'ionic-team/ionicons',\n",
    "             'designmodo/Flat-UI',\n",
    "             'h5bp/html5-boilerplate',\n",
    "             'foundation/foundation-sites',\n",
    "             'Modernizr/Modernizr',\n",
    "             'twbs/ratchet',\n",
    "             'IanLunn/Hover',\n",
    "             'connors/photon',\n",
    "             'basscss/basscss',\n",
    "             'atlemo/SubtlePatterns',\n",
    "             'mrmrs/colors',\n",
    "             'beetbox/beets',\n",
    "             'scottschiller/SoundManager2',\n",
    "             'CreateJS/SoundJS',\n",
    "             'musescore/MuseScore',\n",
    "             'tomahawk-player/tomahawk',\n",
    "             'cashmusic/platform',\n",
    "             'mopidy/mopidy',\n",
    "             'AudioKit/AudioKit',\n",
    "             'Soundnode/soundnode-app',\n",
    "             'gillesdemey/Cumulus',\n",
    "             'metabrainz/picard',\n",
    "             'overtone/overtone',\n",
    "             'samaaron/sonic-pi',\n",
    "             'puppetlabs/puppet',\n",
    "             'chef/chef',\n",
    "             'ansible/ansible',\n",
    "             'saltstack/salt',\n",
    "             'hashicorp/vagrant',\n",
    "             'openstack/openstack',\n",
    "             'moby/moby',\n",
    "             'capistrano/capistrano',\n",
    "             'statsd/statsd',\n",
    "             'graphite-project/graphite-web',\n",
    "             'elastic/logstash',\n",
    "             'fabric/fabric',\n",
    "             'grafana/grafana',\n",
    "             'StackStorm/st2',\n",
    "             'openshift/origin',\n",
    "             'getsentry/sentry',\n",
    "             'deployphp/deployer',\n",
    "             'kubernetes/kubernetes',\n",
    "             'netdata/netdata',\n",
    "             'cloud66-oss/habitus'\n",
    "             \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['puppetlabs/puppet',\n",
       " 'chef/chef',\n",
       " 'ansible/ansible',\n",
       " 'saltstack/salt',\n",
       " 'hashicorp/vagrant',\n",
       " 'openstack/openstack',\n",
       " 'moby/moby',\n",
       " 'capistrano/capistrano',\n",
       " 'statsd/statsd',\n",
       " 'graphite-project/graphite-web',\n",
       " 'elastic/logstash',\n",
       " 'fabric/fabric',\n",
       " 'grafana/grafana',\n",
       " 'StackStorm/st2',\n",
       " 'openshift/origin',\n",
       " 'getsentry/sentry',\n",
       " 'deployphp/deployer',\n",
       " 'kubernetes/kubernetes',\n",
       " 'netdata/netdata',\n",
       " 'cloud66-oss/habitus']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h1 in soup.find_all('h1'):\n",
    "    print(re.sub(r'\\s', '',h1.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all(class_='h3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('a', href=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/AIDungeon/AIDungeon'\n",
    "\n",
    "headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "\n",
    "response = get(url, headers=headers)\n",
    "\n",
    "# print(response.content)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "soup.find('span', class_= 'lang').text\n",
    "\n",
    "soup.find_all('span', class_= 'lang')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# soup.select('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " = []\n",
    "full_beer = []\n",
    "for l in short_list:\n",
    "    url = 'https://github.com/trending/\n",
    "    #source = urllib.request.urlopen('https://untappd.com/beer/top_rated?type={}'.format(l)).read()\n",
    "    headers = {'User-Agent': 'Codeup Data Science Student'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser') \n",
    "    table = soup.find_all(\"div\",{\"class\":\"beer-item\"})\n",
    "    #table_rows = soup.find_all('span',{\"class\":\"num\"})\n",
    "    full_beer.append(beers)\n",
    "    #beers = []\n",
    "    \n",
    "    for t in table:\n",
    "        rating = t.select('span',{\"class\":\"num\"})\n",
    "        name = t.select('a',{\"class\":\"name\"})\n",
    "        brewery = t.select('a',{\"class\":\"style\"})\n",
    "        style = t.select('p',{\"class\":\"style\"})\n",
    "        row_rating = [i.text for i in rating]\n",
    "        row_name = [i.text for i in name]\n",
    "        row_brewery = [i.text for i in brewery]\n",
    "        row_style = [i.text for i in style]\n",
    "        beers.append([row_name[1],row_rating[1],row_brewery[2],row_style[2]])\n",
    "        time.sleep(.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. By the end of this exercise, you should have a file named acquire.py that contains the specified functions. If you wish, you may break your work into separate files for each website (e.g. acquire_codeup_blog.py and acquire_news_articles.py), but the end function should be present in acquire.py (that is, acquire.py should import get_blog_articles from the acquire_codeup_blog module.)\n",
    "\n",
    "Codeup Blog Articles\n",
    "\n",
    "Scrape the article text from the following pages:\n",
    "\n",
    " - https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    " - https://codeup.com/data-science-myths/\n",
    " - https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    " - https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    " - https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\n",
    "\n",
    "Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    "{\n",
    "\n",
    "    'title': 'the title of the article',\n",
    "    \n",
    "    'content': 'the full text content of the article'\n",
    "}\n",
    "\n",
    "\n",
    "Plus any additional properties you think might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Bayes Data Science'} # codeup.com doesn't like our default user-agent\n",
    "response = get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('div.mk-single-content.clearfix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from curriculum for scraping a writing to a text file\n",
    "\n",
    "# def get_article_text():\n",
    "#     # if we already have the data, read it locally\n",
    "#     if os.path.exists('article.txt'):\n",
    "#         with open('article.txt') as f:\n",
    "#             return f.read()\n",
    "\n",
    "#     # otherwise go fetch the data\n",
    "#     url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "#     headers = {'User-Agent': 'Codeup Bayes Data Science'}\n",
    "#     response = get(url, headers=headers)\n",
    "#     soup = BeautifulSoup(response.text)\n",
    "#     article = soup.find('div', class_='mk-single-content')\n",
    "\n",
    "#     # save it for next time\n",
    "#     with open('article.txt', 'w') as f:\n",
    "#         f.write(article.text)\n",
    "\n",
    "#     return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select('div.mk-single-content.clearfix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find finds the first of something or returns None\n",
    "\n",
    ".find_all returns a list of somethings\n",
    "\n",
    ".select returns a list of matching things \n",
    "\n",
    ".select returns an empty list even if there's nothing there\n",
    "\n",
    ".select returns a list even if there's only one thing\n",
    "\n",
    ".select_one returns the first match from the CSS in .select\n",
    "\n",
    "soup.find('div', class_='mk-single-content')\n",
    "\n",
    "soup.select(\"div.mk-single-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(url):\n",
    "    \n",
    "    # assign headers so that the codeup website allows us in\n",
    "    headers = {'User-Agent': 'Codeup Bayes Data Science'}\n",
    "    \n",
    "    # creates response object\n",
    "    response = get(url, headers=headers)\n",
    "    \n",
    "    # takes string of html and turns into a beautiful soup object so we can have access to the soup functions and properties\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # create a variable title. Can use select instead but it returns a list, so you need to step down into it with [0]\n",
    "    title = soup.find('title').text\n",
    "    \n",
    "    # create a variable body.  Can also use select ie: soup.select('div.mk-single-content.clearfix')\n",
    "    body = soup.find('div', class_='mk-single-content').get_text()\n",
    "    \n",
    "    # returning a dictionary literal\n",
    "    return {'title': title, 'body': body}\n",
    "\n",
    "#     Can also use this to return a dictionary.  Can loop through this, whereas you cant on the the one above\n",
    "#     output = {}\n",
    "#     output['title'] = title\n",
    "#     output['body'] = body\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles():\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    urls = [\n",
    "        \"https://codeup.com/codeups-data-science-career-accelerator-is-here/\",\n",
    "        \"https://codeup.com/data-science-myths/\",\n",
    "        \"https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\",\n",
    "        \"https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\",\n",
    "        \"https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\",\n",
    "    ]\n",
    "    \n",
    "    for url in urls:\n",
    "        # Can also use extend.  So if you bring in another list, it flattens it and adds it to the same list\n",
    "        # whereas append throws the list inside of the original list\n",
    "        articles.append(create_dictionary(url))\n",
    "    \n",
    "    df = pd.DataFrame(articles, columns=['title', 'body'])\n",
    "    \n",
    "    return articles, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles, df = get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('blog_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can start cleaning and preparing the data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.body.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('articles.json', 'w') as fout:\n",
    "#     json.dump(articles , fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:\n",
    "\n",
    "Scrape the text of all the articles linked on codeup's blog page.\n",
    "\n",
    "### Bonus Bonus:\n",
    "\n",
    "Starting from the blog homepage, scrape the full text of every article linked on the page, then move on to the next page and keep doing the same thing until you have scraped the entire text of Codeup's blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. News Articles\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    " - Business\n",
    " - Sports\n",
    " - Technology\n",
    " - Entertainment\n",
    " \n",
    "The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    "{\n",
    "\n",
    "    'title': 'The article title',\n",
    "    \n",
    "    'content': 'The article content',\n",
    "    \n",
    "    'category': 'business' # for example\n",
    "    \n",
    "}\n",
    "\n",
    "Hints:\n",
    "\n",
    " - Start by inspecting the website in your browser. Figure out which elements will be useful.\n",
    " - Start by creating a function that handles a single article and produces a dictionary like the one above.\n",
    " - Next create a function that will find all the articles on a single page and call the function you created in the last step for every article on the page.\n",
    " - Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bonus: cache the data\n",
    "\n",
    "Write your code such that the acquired data is saved locally in some form or fashion. Your functions that retrieve the data should prefer to read the local data instead of having to make all the requests everytime the function is called. Include a boolean flag in the functions to allow the data to be acquired \"fresh\" from the actual sources (re-writing your local cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles():\n",
    "    filename = 'inshorts_news_articles.csv'\n",
    "\n",
    "    # check for presence of the file or make a new request\n",
    "    if os.path.exists(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        return make_new_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_from_topic(url):\n",
    "    headers = {'user-agent': 'Codeup Bayes Instructor Example'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    output = []\n",
    "\n",
    "    articles = soup.select(\".news-card\")\n",
    "\n",
    "    for article in articles: \n",
    "        title = article.select(\"[itemprop='headline']\")[0].get_text()\n",
    "        content = article.select(\"[itemprop='articleBody']\")[0].get_text()\n",
    "        author = article.select(\".author\")[0].get_text()\n",
    "        published_date = article.select(\".time\")[0][\"content\"]\n",
    "        category = response.url.split(\"/\")[-1]\n",
    "\n",
    "        article_data = {\n",
    "            'title': title,\n",
    "            'content': content,\n",
    "            'category': category,\n",
    "            'author': author,\n",
    "            'published_date': published_date,\n",
    "        }\n",
    "        output.append(article_data)\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_request():\n",
    "    urls = [\n",
    "        \"https://inshorts.com/en/read/business\",\n",
    "        \"https://inshorts.com/en/read/sports\",\n",
    "        \"https://inshorts.com/en/read/technology\",\n",
    "        \"https://inshorts.com/en/read/entertainment\"\n",
    "    ]\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    for url in urls:\n",
    "        # We use .extend in order to make a flat output list.\n",
    "        output.extend(get_articles_from_topic(url))\n",
    "\n",
    "    print(\"stuff\")\n",
    "    print(output)\n",
    "    df = pd.DataFrame(output)\n",
    "    df.to_csv('inshorts_news_articles.csv') \n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
