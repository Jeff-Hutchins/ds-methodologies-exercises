{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.copy() to copy a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://site-to-scrape.glitch.me/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Codeup Data Science Student'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "  <head>\n",
      "    <title>Site to Scrape!</title>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "    \n",
      "    <!-- import the webpage's stylesheet -->\n",
      "    <link rel=\"stylesheet\" href=\"/style.css\">\n",
      "    \n",
      "    <!-- import the webpage's javascript file -->\n",
      "    <script src=\"/script.js\" defer></script>\n",
      "  </head>  \n",
      "  <body>\n",
      "    <header>\n",
      "      <h1>This is the header!</h1>\n",
      "      <hr>\n",
      "    </header>\n",
      "    \n",
      "    <main>\n",
      "      <div>\n",
      "        <h1 class=\"first\">\n",
      "        This is the main\n",
      "        </h1>\n",
      "        <h2>\n",
      "          This is an h2 of main\n",
      "        </h2>\n",
      "        <h3>\n",
      "          H3 inside of first div inside of main\n",
      "        </h3>\n",
      "      </div>\n",
      "      <div>\n",
      "        <h3 class=\"first\">\n",
      "          H3 inside of second div inside of main.\n",
      "        </h3>\n",
      "        <p>\n",
      "          Here's some text content for us to scrape! üëΩ\n",
      "        </p>\n",
      "        <p>\n",
      "          Here's another paragraph of content! ‚ò†Ô∏è\n",
      "        </p>\n",
      "        <a href=\"https://ryanorsinger.com\">Click here to visit my homepage</a>       \n",
      "      </div>\n",
      "    </main>\n",
      "\n",
      "    <footer>\n",
      "      <h1>This is the footer</h1>\n",
      "      <img src=\"https://traffic-analytics.glitch.me/counter.png?fallback=MY_WEBSITE&color=black\" alt=\"\" style=\"vertical-align: bottom;\" aria-hidden=\"true\">\n",
      "    </footer>\n",
      "\n",
      "  </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n          This is an h2 of main\\n        '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. By the end of this exercise, you should have a file named acquire.py that contains the specified functions. If you wish, you may break your work into separate files for each website (e.g. acquire_codeup_blog.py and acquire_news_articles.py), but the end function should be present in acquire.py (that is, acquire.py should import get_blog_articles from the acquire_codeup_blog module.)\n",
    "\n",
    "Codeup Blog Articles\n",
    "\n",
    "Scrape the article text from the following pages:\n",
    "\n",
    " - https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    " - https://codeup.com/data-science-myths/\n",
    " - https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    " - https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    " - https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\n",
    "\n",
    "Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    "{\n",
    "\n",
    "    'title': 'the title of the article',\n",
    "    \n",
    "    'content': 'the full text content of the article'\n",
    "}\n",
    "\n",
    "\n",
    "Plus any additional properties you think might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Bayes Data Science'} # codeup.com doesn't like our default user-agent\n",
    "response = get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup‚Äôs Data Science Career Accelerator is Here! - Codeup'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeup‚Äôs Data Science Career Accelerator is Here! - Codeup'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en-US\" >\n",
      "<head>\n",
      "\t\t<meta charset=\"UTF-8\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=0\" /><meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" /><meta name=\"format-detection\" content=\"telephone=no\"><title>Codeup‚Äôs Data Science Career Accelerator is Here! - Codeup</title>\n",
      "<script type=\"text/javascript\">var ajaxurl = \"https://codeup.com/wp-admin/admin-ajax.php\";</script>\n",
      "\t\t<style id=\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from curriculum for scraping a writing to a text file\n",
    "\n",
    "# def get_article_text():\n",
    "#     # if we already have the data, read it locally\n",
    "#     if os.path.exists('article.txt'):\n",
    "#         with open('article.txt') as f:\n",
    "#             return f.read()\n",
    "\n",
    "#     # otherwise go fetch the data\n",
    "#     url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "#     headers = {'User-Agent': 'Codeup Bayes Data Science'}\n",
    "#     response = get(url, headers=headers)\n",
    "#     soup = BeautifulSoup(response.text)\n",
    "#     article = soup.find('div', class_='mk-single-content')\n",
    "\n",
    "#     # save it for next time\n",
    "#     with open('article.txt', 'w') as f:\n",
    "#         f.write(article.text)\n",
    "\n",
    "#     return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select('div.mk-single-content.clearfix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find finds the first of something or returns None\n",
    "\n",
    ".find_all returns a list of somethings\n",
    "\n",
    ".select returns a list of matching things \n",
    "\n",
    ".select returns an empty list even if there's nothing there\n",
    "\n",
    ".select returns a list even if there's only one thing\n",
    "\n",
    ".select_one returns the first match from the CSS in .select\n",
    "\n",
    "soup.find('div', class_='mk-single-content')\n",
    "\n",
    "soup.select(\"div.mk-single-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(url):\n",
    "    \n",
    "    # assign headers so that the codeup website allows us in\n",
    "    headers = {'User-Agent': 'Codeup Bayes Data Science'}\n",
    "    \n",
    "    # creates response object\n",
    "    response = get(url, headers=headers)\n",
    "    \n",
    "    # takes string of html and turns into a beautiful soup object so we can have access to the soup functions and properties\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # create a variable title. Can use select instead but it returns a list, so you need to step down into it with [0]\n",
    "    title = soup.find('title').text\n",
    "    \n",
    "    # create a variable body.  Can also use select ie: soup.select('div.mk-single-content.clearfix')\n",
    "    body = soup.find('div', class_='mk-single-content').get_text()\n",
    "    \n",
    "    # returning a dictionary literal\n",
    "    return {'title': title, 'body': body}\n",
    "\n",
    "#     Can also use this to return a dictionary.  Can loop through this, whereas you cant on the the one above\n",
    "#     output = {}\n",
    "#     output['title'] = title\n",
    "#     output['body'] = body\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles():\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    urls = [\n",
    "        \"https://codeup.com/codeups-data-science-career-accelerator-is-here/\",\n",
    "        \"https://codeup.com/data-science-myths/\",\n",
    "        \"https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\",\n",
    "        \"https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\",\n",
    "        \"https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\",\n",
    "    ]\n",
    "    \n",
    "    for url in urls:\n",
    "        # Can also use extend.  So if you bring in another list, it flattens it and adds it to the same list\n",
    "        # whereas append throws the list inside of the original list\n",
    "        articles.append(create_dictionary(url))\n",
    "    \n",
    "    df = pd.DataFrame(articles, columns=['title', 'body'])\n",
    "    \n",
    "    return articles, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles, df = get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Codeup‚Äôs Data Science Career Accelerator is Here! - Codeup',\n",
       "  'body': '\\nThe rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor‚Äôs #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We‚Äôve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee ‚Äì just like our existing Web Dev program. We‚Äôre focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning ‚Äì regression; 6) Supervised machine learning ‚Äì classification; 7) Unsupervised machine learning ‚Äì clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup‚Äôs first Data Science cohort, which will start class on February 4, 2019. Hurry ‚Äì there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n'},\n",
       " {'title': 'Data Science Myths - Codeup',\n",
       "  'body': '\\nBy Dimitri Antoniou and Maggie Giust\\nData Science, Big Data, Machine Learning, NLP, Neural Networks‚Ä¶these buzzwords have rapidly spread into mainstream use over the last few years. Unfortunately, definitions are varied and sources of truth are limited. Data Scientists are in fact not magical unicorn wizards who can snap their fingers and turn a business around! Today, we‚Äôll take a cue from our favorite Mythbusters to tackle some common myths and misconceptions in the field of Data Science.\\n\\nvia GIPHY\\nMyth #1: Data Science = Statistics\\nAt first glance, this one doesn‚Äôt sound unreasonable. Statistics is defined as, ‚ÄúA branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data.‚Äù That sounds a lot like our definition of Data Science: a method of drawing actionable intelligence from data. \\nIn truth, statistics is actually one small piece of Data Science. As our Senior Data Scientist puts it, ‚ÄúStatistics forces us to make assumptions about the nature of the relationship between variables, the distribution of the data, etc.‚Äù In the traditional Data Science venn diagram, you‚Äôll see that math/stats make up ‚Öì of a working professional. These are tools and skills to leverage, but data science itself is about drawing intelligence from data.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #2: Data Scientist = Business/Data Analyst\\nThis one is so common that we wrote a whole post about it! These are separate and different roles within the data field. While a data scientist will often do analytics, their spectrum of work is wider. A data analyst will use structured data to create dashboards and KPIs, while a Data Scientist deals with unstructured and messy data for a range of outputs. If they‚Äôre interested, business analysts will often progress to data scientists.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #3: Data Science = Data Science\\nThis one‚Äôs tricky, because it‚Äôs impossible to either confirm or bust! The ‚Äòmyth‚Äô is that one person or company using the term Data Science is not necessarily the same as another person or company using the same term. Depending on organizational capacity, individual experience, educational background, and many other variables, we might be using the same name for different animals.\\nTl;dr: don‚Äôt assume a common understanding across hiring managers, recruiters, and practitioners. Look instead for specifics of tools, techniques, methodologies, and outputs. That being said, this one falls in the ‚Äúplausible‚Äù category, because it may actually be true in some circumstances, while false in others.\\nPLAUSIBLE\\n\\nvia GIPHY\\n\\xa0\\nMyth #4: Data Science curricula are well-defined and consistent.\\nWe recommend checking this one out for yourself! A quick google search for bootcamps, master‚Äôs degree programs, and online courses will reveal that different organizations teach different things. There is no commonly accepted framework for teaching data science! Some focus more on the engineering, others focus more on machine learning, some think deep learning is foundational, and some prefer to use R. \\nOur curriculum was built through employer interviews, practitioner interviews, market research, and company partnerships. But we‚Äôre based in San Antonio! A bootcamp in New York might follow the same process and end up with a different syllabus. Keep in mind, whatever your learning path, that there will be gaps in your learning. The most important thing is to recognize those gaps.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #5: If I want to be a data scientist, I just need to learn Python or R.\\nThis one is common and dangerous! Just like statistics, programming languages like Python and R are tools. They‚Äôre just pieces of a larger puzzle! Knowing Python without understanding the data science pipeline is like knowing how to build a floor without having a floor plan. Of course, these are valuable technical skills that give you a leg up, but they‚Äôre second in importance to asking the right questions, knowing what tools to use when, and communicating your findings.\\nBUSTED\\n\\nvia GIPHY\\nStill have questions? Reach out to us at (210) 802-7289 or DataScience@codeup.com! Want to learn more about Data Science? Check out our recent blog posts at tribucodeup.wpengine.com/blog. And of course, if data science gets you excited, get started with us today at tribucodeup.wpengine.com/apply!\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n \\n\\nSan Antonio: 600 Navarro St. #600, San Antonio, Texas \\n\\n \\n\\n \\n\\n \\n\\n|   info@codeup.com \\n\\n   |   210 - 802 - 7289   \\n\\n \\n\\nDallas: 701 Commerce St #100A, Dallas, TX 75202 \\n\\n\\n \\nvar htmlDiv = document.getElementById(\"rs-plugin-settings-inline-css\"); var htmlDivCss=\"\";\\r\\n\\t\\t\\t\\tif(htmlDiv) {\\r\\n\\t\\t\\t\\t\\thtmlDiv.innerHTML = htmlDiv.innerHTML + htmlDivCss;\\r\\n\\t\\t\\t\\t}else{\\r\\n\\t\\t\\t\\t\\tvar htmlDiv = document.createElement(\"div\");\\r\\n\\t\\t\\t\\t\\thtmlDiv.innerHTML = \"<style>\" + htmlDivCss + \"</style>\";\\r\\n\\t\\t\\t\\t\\tdocument.getElementsByTagName(\"head\")[0].appendChild(htmlDiv.childNodes[0]);\\r\\n\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\n\\r\\nif (setREVStartSize!==undefined) setREVStartSize(\\r\\n\\t{c: \\'#rev_slider_1_1\\', responsiveLevels: [1240,1024,778,480], gridwidth: [1240,1024,778,480], gridheight: [283,283,239,239], sliderLayout: \\'fullwidth\\'});\\r\\n\\t\\t\\t\\r\\nvar revapi1,\\r\\n\\ttpj;\\t\\r\\n(function() {\\t\\t\\t\\r\\n\\tif (!/loaded|interactive|complete/.test(document.readyState)) document.addEventListener(\"DOMContentLoaded\",onLoad); else onLoad();\\t\\r\\n\\tfunction onLoad() {\\t\\t\\t\\t\\r\\n\\t\\tif (tpj===undefined) { tpj = jQuery; if(\"off\" == \"on\") tpj.noConflict();}\\r\\n\\tif(tpj(\"#rev_slider_1_1\").revolution == undefined){\\n\\t\\trevslider_showDoubleJqueryError(\"#rev_slider_1_1\");\\n\\t}else{\\n\\t\\trevapi1 = tpj(\"#rev_slider_1_1\").show().revolution({\\n\\t\\t\\tsliderType:\"hero\",\\n\\t\\t\\tjsFileLocation:\"//codeup.com/wp-content/plugins/revslider/public/assets/js/\",\\n\\t\\t\\tsliderLayout:\"fullwidth\",\\n\\t\\t\\tdottedOverlay:\"none\",\\n\\t\\t\\tdelay:9000,\\n\\t\\t\\tresponsiveLevels:[1240,1024,778,480],\\n\\t\\t\\tvisibilityLevels:[1240,1024,778,480],\\n\\t\\t\\tgridwidth:[1240,1024,778,480],\\n\\t\\t\\tgridheight:[283,283,239,239],\\n\\t\\t\\tlazyType:\"none\",\\n\\t\\t\\tshadow:0,\\n\\t\\t\\tspinner:\"spinner0\",\\n\\t\\t\\tautoHeight:\"off\",\\n\\t\\t\\tdisableProgressBar:\"on\",\\n\\t\\t\\thideThumbsOnMobile:\"off\",\\n\\t\\t\\thideSliderAtLimit:0,\\n\\t\\t\\thideCaptionAtLimit:0,\\n\\t\\t\\thideAllCaptionAtLilmit:0,\\n\\t\\t\\tdebugMode:false,\\n\\t\\t\\tfallbacks: {\\n\\t\\t\\t\\tsimplifyAll:\"off\",\\n\\t\\t\\t\\tdisableFocusListener:false,\\n\\t\\t\\t}\\n\\t\\t});\\n\\t}; /* END OF revapi call */\\n\\t\\n }; /* END OF ON LOAD FUNCTION */\\r\\n}()); /* END OF WRAPPING FUNCTION */\\r\\n\\n\\n'},\n",
       " {'title': 'Data Science VS Data Analytics: What‚Äôs The Difference? - Codeup',\n",
       "  'body': '\\nBy Dimitri Antoniou\\nA week ago, Codeup launched our immersive Data Science career accelerator! With our first class kicking off in February and only 25 seats available, we‚Äôve been answering a lot of questions from prospective students. One in particular has come up so many times we decided to dedicate a blog post to it. What is the difference between data science and data analytics?\\nFirst, let‚Äôs define some of our terms! Take a look at this blog to understand what Data Science is. In short, it is a method of turning raw data into action, leading to a desired outcome. Big Data refers to data sets that are large and complex, usually exceeding the capacity of computers and normal processing power to deal with. Machine Learning is the process of ‚Äòlearning‚Äô underlying patterns of data in order to automate the extraction of intelligence from that data.\\n\\nNow, let‚Äôs look at the data pipeline that data scientists work through to reach the actionable insights and outcomes we mentioned:\\n\\nWe start by collecting data, which may come from social media channels, network logs, financials, employee records, or more.\\nWe then process that data into usable information stored in databases or streamed.\\nNext, we look back on the history of that data to summarize, describe, and explain, turning the data into meaningful knowledge. Here we‚Äôre primarily using mathematics, statistics, and visualization methods.\\nNow we convert that knowledge into intelligence, seeking to predict future events so that we can make decisions in the present. This is where practitioners will introduce mathematical/statistical modeling through machine learning to their data.\\nFinally, we enable action by building automations, running tests, building visualizations, monitoring new data, etc.\\n\\nData professionals work at different stages of the spectrum to move data through the pipeline. On the left, Big Data Engineers specialize in collecting, storing, and processing data, getting it from Data to Information. In the middle, analysts work to understand and convert that information to knowledge. Lastly, a Machine Learning Engineer utilizes machine learning algorithms to turn intelligence into action by building automations, visualizations, recommendations, and predictions.\\nData Scientists span multiple stages of this pipeline, from information to action. They will spend about 70% of their time wrangling data in the information stage. They will conduct statistical analysis to derive knowledge. Lastly, they predict future events and build automations using machine learning.\\nFor those technical folk out there, data science is to data engineering or machine learning engineering as full-stack development is to front-end or back-end development. For the non-technical folk, data science is the umbrella term that houses data analytics, machine learning, and other data professions.\\nSo what‚Äôs the biggest difference between a data analyst and a data scientist? Data scientists utilize computer programming and machine learning in addition to mathematics and statistics. \\nStill have questions? Reach out to us at (210) 802-7289 or DataScience@codeup.com! Wondering which of Codeup‚Äôs programs is right for you? We‚Äôve got you covered. And of course, if data science gets you excited, get started with us today at tribucodeup.wpengine.com/apply!\\n'},\n",
       " {'title': '10 Tips to Crush It at the SA Tech Job Fair - Codeup',\n",
       "  'body': '\\n10 Tips to Crush It at the SA Tech Job Fair\\nSA Tech Job Fair\\nThe third bi-annual San Antonio Tech Job Fair is just around the corner. Over 25 companies will be at The Jack Guenther Pavilion\\xa0on April 10th, and they are hungry for new tech team members!\\nAt the job fair, companies want to quickly source a list of new talent leads. AKA they need to find qualified employees they can begin interviewing for jobs. Recruiters will represent their organization at tables with informational handouts and company swag. Your goal at a job fair is to set yourself apart from other candidates and ensure your name makes it to the top of those lead lists.\\nThink of your interaction with the company as a mini screening interview. The company rep will subtly evaluate basic qualities like your professionalism, communication and interpersonal skills, work experience, and interest level in the organization. Job fairs are also an opportunity for you to gain information about companies that may not be easily accessible online. \\xa0\\nAt Codeup, we‚Äôre passionate about bridging the gap between talent and demand, so we‚Äôve outlined 10 tips to ensure you bring your A-game and leave a lasting impression!\\n10 Tips for Totally Crushing it at the SA Tech Job Fair\\n\\nUse keywords to describe your skills, but don‚Äôt go overboard. You‚Äôll probably be talking to a recruiter or talent acquisition specialist. As a technical candidate, recognize these individuals usually aren‚Äôt developers or network administrators. They know terms like ‚ÄúJavaScript‚Äù and ‚ÄúApache,‚Äù but haven‚Äôt written a line of code or spun up a server, so don‚Äôt get too caught up in industry jargon.\\nResearch the companies ahead of time. Review the list of attending companies and make sure you know what the company does and whether or not they hire people in your desired role. Look up recent news on the company and mention it during your conversation.\\nDefine your own goals for the job fair. Are you searching for a specific type of role or company culture? What matters most in your job search? Are there companies you want to prioritize? \\xa0Develop a game plan and be intentional with your time.\\nPrepare a stellar r√©sum√©. Bring about 20 copies of your r√©sum√© to the event, printed on nice paper. We won‚Äôt cover resume writing in this post, but there are a plethora of online resources you can consult. For job fairs, don‚Äôt worry about cover letters.\\nPolish your online profiles. If recruiters have a copy of your resume, you can be sure they will stalk you online soon. Make sure your online presence is professional and appropriate. A good place to start is by Googling yourself. Update your LinkedIn, and clean up any social media profiles.\\nCraft a 30-60 second elevator pitch. You may only have a few minutes with an employer. What will you say if they ask, ‚ÄúTell me about yourself?‚Äù Consider structuring your pitch like this: Who you are + What you do + What your goals are + Why that matters to the company.\\nDon‚Äôt show up in a t-shirt, but trade in your suit for something more chill. Always keep it professional, but remember: tech is typically more casual than other industries. You‚Äôll likely feel out of place if you look like you belong on Wall St., so refer to this guide on dressing for tech interviews.\\nDon‚Äôt forget the basics. Start and end each conversation with a firm handshake. Make eye contact while conversing. Smile! Thank the recruiter before you move on to the next table.\\nAsk educated questions. Don‚Äôt waste valuable face time with recruiters by asking questions like, ‚ÄúWhat does [Insert Company here] do?‚Äù They hate that question! Instead, try some of these:\\n\\nWhat are the top 3-5 examples of knowledge, skills, and abilities you look for in candidates?\\nWhat‚Äôs the best advice you have for someone who wants to work here?\\nWhat is your interview process like?\\nAre you hiring for any roles not currently listed on your websites?\\n\\n\\nFollow up. Collect business cards from each table. The next day, send a short note expressing your interest in the company‚Äôs opportunities and thanking the recruiter for his or her time.\\n\\nRSVP for the SA Tech Job Fair taking place at the Jack Guenther Pavilion ‚Äì September 18th starting at 4 pm.\\xa0\\n'},\n",
       " {'title': 'Competitor Bootcamps Are Closing. Is the Model in Danger? - Codeup',\n",
       "  'body': '\\nCompetitor Bootcamps Are Closing. Is the Model in Danger?\\n\\xa0\\n\\nIs the programming bootcamp model in danger?\\nIn recent news, DevBootcamp and The Iron Yard announced that they are closing their doors. This is big news. DevBootcamp was the first programming bootcamp model and The Iron Yard is a national player with 15 campuses across the U.S. In both cases, the companies cited an unsustainable business model. Does that mean the boot-camp model is dead?\\n\\ntl;dr ‚ÄúNope!‚Äù\\nBootcamps exist because traditional education models have failed to provide students job-ready skills for the 21st century. Students demand better employment options from their education. Employers demand skilled and job ready candidates. Big Education‚Äôs failure to meet those needs through traditional methods created the fertile ground for the new business model of the programming bootcamp.\\nEducation giant Kaplan and Apollo Education Group (owner of University of Phoenix) bought their way into this new educational model when they purchased The Iron Yard and DevBootcamp. They purchased their competition with the intent to scale up the model. Unfortunately, Big Education is too habituated to coming up short for students. They bought the upstarts that challenged them, tried making changes to run those bootcamps in the ‚ÄúBig Education‚Äù way, and, sadly, they‚Äôve closed the doors when they realized that scaling education is more challenging when student outcomes truly matter.\\nThe bootcamp model is still new and there will be plenty consolidation, competition, and changes in the future. This model is based on actually being adaptive, innovative, and sustainable. And there‚Äôs always room for innovation.\\n\\n\\nWhat we‚Äôve learned at Codeup‚Ä¶\\n\\n\\nEducation is challenging to scale.\\nPrioritizing quality over growth pays off.\\n\\nWhat we‚Äôre doing at Codeup‚Ä¶\\n\\nHigher standards in our application process are leading to better student outcomes.\\nOur reputation and commitment to quality is opening new doors to previously uninterested/unreachable employers.\\nIn the beginning, the majority of Codeup graduates went to work with startups and small businesses. We‚Äôre now seeing a larger amount of our graduates place at medium to large sized businesses.\\nDemand is growing and employers are learning that the results are in the graduates.\\nCodeup‚Äôs model is sustainable, inclusive, and works.\\n\\nCall or contact us today to see how Codeup‚Äôs commitment to quality and approach to being a career accelerator can make a profound difference in your life.\\n'}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup‚Äôs Data Science Career Accelerator is He...</td>\n",
       "      <td>\\nThe rumors are true! The time has arrived. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths - Codeup</td>\n",
       "      <td>\\nBy Dimitri Antoniou and Maggie Giust\\nData S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What‚Äôs The Dif...</td>\n",
       "      <td>\\nBy Dimitri Antoniou\\nA week ago, Codeup laun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair - ...</td>\n",
       "      <td>\\n10 Tips to Crush It at the SA Tech Job Fair\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td>\\nCompetitor Bootcamps Are Closing. Is the Mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup‚Äôs Data Science Career Accelerator is He...   \n",
       "1                        Data Science Myths - Codeup   \n",
       "2  Data Science VS Data Analytics: What‚Äôs The Dif...   \n",
       "3  10 Tips to Crush It at the SA Tech Job Fair - ...   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                                body  \n",
       "0  \\nThe rumors are true! The time has arrived. C...  \n",
       "1  \\nBy Dimitri Antoniou and Maggie Giust\\nData S...  \n",
       "2  \\nBy Dimitri Antoniou\\nA week ago, Codeup laun...  \n",
       "3  \\n10 Tips to Crush It at the SA Tech Job Fair\\...  \n",
       "4  \\nCompetitor Bootcamps Are Closing. Is the Mod...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('blog_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can start cleaning and preparing the data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The rumors are true! The time has arrived. Cod...\n",
       "1    By Dimitri Antoniou and Maggie Giust\\nData Sci...\n",
       "2    By Dimitri Antoniou\\nA week ago, Codeup launch...\n",
       "3    10 Tips to Crush It at the SA Tech Job Fair\\nS...\n",
       "4    Competitor Bootcamps Are Closing. Is the Model...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('articles.json', 'w') as fout:\n",
    "#     json.dump(articles , fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:\n",
    "\n",
    "Scrape the text of all the articles linked on codeup's blog page.\n",
    "\n",
    "### Bonus Bonus:\n",
    "\n",
    "Starting from the blog homepage, scrape the full text of every article linked on the page, then move on to the next page and keep doing the same thing until you have scraped the entire text of Codeup's blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. News Articles\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    " - Business\n",
    " - Sports\n",
    " - Technology\n",
    " - Entertainment\n",
    " \n",
    "The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    "{\n",
    "\n",
    "    'title': 'The article title',\n",
    "    \n",
    "    'content': 'The article content',\n",
    "    \n",
    "    'category': 'business' # for example\n",
    "    \n",
    "}\n",
    "\n",
    "Hints:\n",
    "\n",
    " - Start by inspecting the website in your browser. Figure out which elements will be useful.\n",
    " - Start by creating a function that handles a single article and produces a dictionary like the one above.\n",
    " - Next create a function that will find all the articles on a single page and call the function you created in the last step for every article on the page.\n",
    " - Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bonus: cache the data\n",
    "\n",
    "Write your code such that the acquired data is saved locally in some form or fashion. Your functions that retrieve the data should prefer to read the local data instead of having to make all the requests everytime the function is called. Include a boolean flag in the functions to allow the data to be acquired \"fresh\" from the actual sources (re-writing your local cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles():\n",
    "    filename = 'inshorts_news_articles.csv'\n",
    "\n",
    "    # check for presence of the file or make a new request\n",
    "    if os.path.exists(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        return make_new_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_from_topic(url):\n",
    "    headers = {'user-agent': 'Codeup Bayes Instructor Example'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    output = []\n",
    "\n",
    "    articles = soup.select(\".news-card\")\n",
    "\n",
    "    for article in articles: \n",
    "        title = article.select(\"[itemprop='headline']\")[0].get_text()\n",
    "        content = article.select(\"[itemprop='articleBody']\")[0].get_text()\n",
    "        author = article.select(\".author\")[0].get_text()\n",
    "        published_date = article.select(\".time\")[0][\"content\"]\n",
    "        category = response.url.split(\"/\")[-1]\n",
    "\n",
    "        article_data = {\n",
    "            'title': title,\n",
    "            'content': content,\n",
    "            'category': category,\n",
    "            'author': author,\n",
    "            'published_date': published_date,\n",
    "        }\n",
    "        output.append(article_data)\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_request():\n",
    "    urls = [\n",
    "        \"https://inshorts.com/en/read/business\",\n",
    "        \"https://inshorts.com/en/read/sports\",\n",
    "        \"https://inshorts.com/en/read/technology\",\n",
    "        \"https://inshorts.com/en/read/entertainment\"\n",
    "    ]\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    for url in urls:\n",
    "        # We use .extend in order to make a flat output list.\n",
    "        output.extend(get_articles_from_topic(url))\n",
    "\n",
    "    print(\"stuff\")\n",
    "    print(output)\n",
    "    df = pd.DataFrame(output)\n",
    "    df.to_csv('inshorts_news_articles.csv') \n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
