{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Data Acquisition\n",
    "\n",
    "This exercises uses the case.csv, dept.csv, and source.csv files from the san antonio 311 call dataset.\n",
    "\n",
    "1. Read the case, department, and source data into their own spark dataframes.\n",
    "\n",
    "2. Let's see how writing to the local disk works in spark:\n",
    "\n",
    "    - Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json\n",
    "    - Inspect your folder structure. What do you notice?\n",
    "\n",
    "3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types.\n",
    "\n",
    "____________________________________________________________________________________________________________\n",
    "\n",
    "1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?\n",
    "\n",
    "2. How many Stray Animal cases are there?\n",
    "\n",
    "3. How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?\n",
    "\n",
    "4. Convert the council_district column to a string column.\n",
    "\n",
    "5. Extract the year from the case_closed_date column.\n",
    "\n",
    "6. Convert num_days_late from days to hours in new columns num_hours_late.\n",
    "\n",
    "7. Join the case data with the source and department data.\n",
    "\n",
    "8. Are there any cases that do not have a request source?\n",
    "\n",
    "9. What are the top 10 service request types in terms of number of requests?\n",
    "\n",
    "10. What are the top 10 service request types in terms of average days late?\n",
    "\n",
    "11. Does number of days late depend on department?\n",
    "\n",
    "12. How do number of days late depend on department and request type?\n",
    "\n",
    "\n",
    "You might have noticed that the latest date in the dataset is fairly far off from the present day. To account for this, replace any occurances of the current time with the maximum date from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the case, department, and source data into their own spark dataframes.\n",
    "\n",
    "2. Let's see how writing to the local disk works in spark:\n",
    "\n",
    "    - Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json\n",
    "    - Inspect your folder structure. What do you notice?\n",
    "\n",
    "\n",
    "3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.10.17.146:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1215132e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
