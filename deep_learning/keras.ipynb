{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Workflow:\n",
    "0. Prep and load your data (turn stuff into tensors)\n",
    "1. Create the model (blank model)\n",
    "2. Add your layer(s) with .add (specify the input shape)\n",
    "3. Compile the model with .compile (configuring the learning paramets)\n",
    "4. Fit the model to the training data with .fit\n",
    "5. Evaluate that modelâ€™s performance with .evaluate\n",
    "6. Produce predictions on the new data w/ .predict\n",
    "7. Decode the predicted data (if necessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is to Tensorflow, as Seaborn is to Matplotlib\n",
    "\n",
    "Tensorflow -> google\n",
    "\n",
    "Pytorch -> Facebook\n",
    "\n",
    "MXNet -> apache and amaon uses MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.datasets import mnist # bring in the MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire the data set\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# explore the shape of the data\n",
    "print(train_images.shape)\n",
    "# print(train_images[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes random wegihts\n",
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A loss function\n",
    "How the network will bea ble to emeasure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "\n",
    "#### An optimizer\n",
    "THe mechanism through which teh network will update itself based on the data it sees and its loss function.\n",
    "\n",
    "#### Metrics to monitor during training and testing\n",
    "Here, we'll only care about accuracy (the fraction of the images that were correctly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our network, specifying the optimizer, loss function, and metrics we want\n",
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the labels as categorical values\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/17\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2620 - acc: 0.9232\n",
      "Epoch 2/17\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.1046 - acc: 0.9684\n",
      "Epoch 3/17\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0691 - acc: 0.9793\n",
      "Epoch 4/17\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0495 - acc: 0.9849\n",
      "Epoch 5/17\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0383 - acc: 0.9882\n",
      "Epoch 6/17\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 7/17\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0220 - acc: 0.9930\n",
      "Epoch 8/17\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 9/17\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0128 - acc: 0.9962\n",
      "Epoch 10/17\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0106 - acc: 0.9968\n",
      "Epoch 11/17\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 12/17\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 13/17\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 14/17\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 15/17\n",
      "60000/60000 [==============================] - 22s 375us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 16/17\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 17/17\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0021 - acc: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x659fa9518>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the training data\n",
    "network.fit(train_images, train_labels, epochs=17, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 63us/step\n",
      "test_acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "# find accuracy of model on train\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
